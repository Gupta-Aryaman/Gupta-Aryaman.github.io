<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Breaking Boundaries | aryaman.space</title>
<meta name="keywords" content="breaking-boundaries, gil, no-gil, python, multithreading, aryaman-batcave">
<meta name="description" content="An in-depth look at Python&#39;s GIL, its impact on performance, and efforts to overcome its limitations including Free-Threading, Gilectomy, and nogil implementations.">
<meta name="author" content="Aryaman Gupta">
<link rel="canonical" href="https://aryaman.space/blog/breaking-boundaries/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://aryaman.space/images/favicon.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://aryaman.space/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://aryaman.space/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://aryaman.space/apple-touch-icon.png">
<link rel="mask-icon" href="https://aryaman.space/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://aryaman.space/blog/breaking-boundaries/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:url" content="https://aryaman.space/blog/breaking-boundaries/">
  <meta property="og:site_name" content="aryaman.space">
  <meta property="og:title" content="Breaking Boundaries">
  <meta property="og:description" content="An in-depth look at Python&#39;s GIL, its impact on performance, and efforts to overcome its limitations including Free-Threading, Gilectomy, and nogil implementations.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2023-12-17T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-12-17T00:00:00+00:00">
    <meta property="article:tag" content="Breaking-Boundaries">
    <meta property="article:tag" content="Gil">
    <meta property="article:tag" content="No-Gil">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="Multithreading">
    <meta property="article:tag" content="Aryaman-Batcave">
      <meta property="og:image" content="https://aryaman.space/images/about.jpg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://aryaman.space/images/about.jpg">
<meta name="twitter:title" content="Breaking Boundaries">
<meta name="twitter:description" content="An in-depth look at Python&#39;s GIL, its impact on performance, and efforts to overcome its limitations including Free-Threading, Gilectomy, and nogil implementations.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://aryaman.space/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Breaking Boundaries",
      "item": "https://aryaman.space/blog/breaking-boundaries/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Breaking Boundaries",
  "name": "Breaking Boundaries",
  "description": "An in-depth look at Python's GIL, its impact on performance, and efforts to overcome its limitations including Free-Threading, Gilectomy, and nogil implementations.",
  "keywords": [
    "breaking-boundaries", "gil", "no-gil", "python", "multithreading", "aryaman-batcave"
  ],
  "articleBody": "Python faces challenges in fully exploiting the growing capabilities of modern hardware. As hardware continues to advance with more CPU cores, faster processors, and abundant memory, Python’s inherent design and execution model can often fall short in taking full advantage of these resources. Its single-threaded nature and certain architectural choices can result in suboptimal performance in scenarios where parallelism and hardware acceleration are vital. This limitation prompts developers to seek alternative solutions, such as integrating Python with external libraries, languages, or technologies, to overcome these hardware-related constraints.\nNeed for Simultaneous Execution in Python Python is widely praised for being easy to learn, easy to use, and highly versatile, supporting developer productivity. However, Python is also notoriously slow. Programs written in languages such as C++, Node.js, and Go can execute as much as 30-40 times faster than equivalent Python programs.\nTable Details Table 1.1: Courtesy of github project by Kostya M Even though Python is constantly being optimized to work faster, we simply can’t rely on the basic single-threaded execution codes as they are too slow. Hence the need for simultaneous execution.\nSimultaneous Execution Possibilities in Python Three big contenders for dealing with multiple tasks in Python:\nAsyncio: In computer programming, asynchrony encompasses events that occur independently of the primary program flow and methods for managing these events. In essence, asynchronization implies that you can proceed with executing other sections of code without the need to wait for a particular task to finish.\nCooperative pausing/waiting Good for I/O bound processes Threading:\nPython runs on a single thread on a single CPU. GIL is a global lock around the entire Python interpreter. In order to advance the interpreter state and run the Python code, a thread must require the GIL. Hence, it is possible to have multiple Python threads in the same process, but only one of them can be executing the Python code. While this happens, the rest must wait to receive the GIL. Non-cooperative pausing/interrupting Good for I/O bound Good for long-running operations without blocking (e.g., GUI applications) Multiprocessing:\nCreate different processes which have their own GIL. Better where all processes are completely independent of each other. Threading Let’s take a for loop as an example, this loop is a CPU-intensive task.\n1 2 3 4 5 6 7 8 9 10 11 # Code 4.1: CPU Intensive task example DO = 100000000 ans = 1 def foo(n): global ans for i in range(n): ans += 2 foo(DO) print(ans) As this was a simple single threaded task, it took around 5 secs and was 99% CPU intensive.\nOkay, so if I have 2 loops like this running on a single thread, it would take around 10s. This is very bad.\n1 2 3 4 5 6 7 8 9 10 11 12 # Code 4.2: Extension of Code 4.1, 2 CPU Intensive tasks DO = 100000000 ans = 1 def foo(n): global ans for i in range(n): ans += 2 foo(DO) foo(DO) print(ans) No issues, as these are CPU intensive tasks, we can run both the tasks on different threads. Hence, simultaneous execution would help us run 2 threads simultaneously and concurrently and the time would be reduced by half.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Code 4.3: CPU Intensive tasks executed in different threads from threading import Thread DO = 100000000 ans = 1 def foo(n): global ans for i in range(n): ans += 2 t1 = Thread(target=foo, args=(DO//2,)) t2 = Thread(target=foo, args=(DO//2,)) t1.start() t2.start() t1.join() t2.join() print(ans) If this was true multithreading, the time taken for a for loop of half the range of the previous example should be half of the previous time taken, i.e. around 2.5 sec.\nBut we can see it again took roughly the same time. Why is this happening? To understand this we need to look into the core concept of Cpython - GIL.\nGIL?! What is GIL? Before discussing GIL, it is important to note that we are discussing this in terms of CPython.\nPython - definition of programming language we know, PEP - python enhancement proposals\nCpython - physical implementation of the ideas in “Python” in C language\nGenerally when we talk about python, we refer to the Cpython implementation of the language only.\nMoving forward -\nFigure DetailsCode 4.1.1: foo function I created a function foo() where I allocated a = 50.\n50 will be stored in memory and the variable a would be pointing to it. So the reference count of the memory where 50 is stored would be 1. But now, when the function is finished, the memory location has to be cleared/dereferenced. Hence, the reference count would be decreased by 1.\nReference counting in CPython - At a very basic level, a Python object’s reference count is incremented whenever the object is referenced, and it’s decremented when an object is dereferenced*.*\nThe memory deallocation is done in different ways in different languages but in python when the reference count of a memory location becomes 0, python knows that that memory location can be used for storing something else.\nExample - Garbage collectors is used by java\nFigure DetailsCode 4.1.2a: Reference Counting Then, why do we get a reference count of ‘a’ as 3 here?\nFigure DetailsFIgure 4.1.1: Reference Counting explanation This is the reason.\nFigure DetailsCode 4.1.2b: Reference Counting The main issue comes, when there is concurrency involved in python threads -\nFigure DetailsFigure 4.1.2: Issue in concurrency in python due to reference counting Imagine 2 threads are running simultaneously, in CPython. Reference Count of memory location pointed by variable ‘a’ is 3. Thread 1 and 2 ask what is the reference count of ‘a’ and both get 3. Now I do ‘b=a’ in thread 1 so the reference count increases to 4. At the same time I do ‘c=a’ in thread 2 and it also updates the reference count to 4.\nBut shouldn’t the reference count be 5? Race conditions occur in such cases. Hence, the requirement for concurrency management or GIL (Global Interpreter Lock) is required\nFigure DetailsFigure 4.1.3: The GLOBAL INTERPRETER LOCK helps maintain reference count In a real scenario if I have 4 threads running concurrently, thread 1 acquires the GIL, does some computation and waits for some I/O. In that time, the GIL is transferred to thread 2 which again does some task and starts waiting for something, for example a mouse click in the GUI. Again the GIL is transferred to a different thread. That’s why multithreading works in cpython.\nBut if I have 2 different threads and both want to work with the CPU, then GIL is not a good option.\nPython 1.0 (1994): Python was initially designed without the GIL. In its early versions, Python used a simple reference counting mechanism for memory management. However, this approach had limitations, especially when dealing with circular references, which could lead to memory leaks.\nPython 1.5 (1999): With Python 1.5, Guido van Rossum, the creator of Python, introduced the Global Interpreter Lock (GIL) as a solution to the multi-threading problems.\nReferring back to the example code 4.3-\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Code 4.3: CPU Intensive tasks executed in different threads from threading import Thread DO = 100000000 ans = 1 def foo(n): global ans for i in range(n): ans += 2 t1 = Thread(target=foo, args=(DO//2,)) t2 = Thread(target=foo, args=(DO//2,)) t1.start() t2.start() t1.join() t2.join() print(ans) If this was true multithreading, the time taken for a for loop of half the range of the previous example should be half of the previous time taken, i.e. around 2.5 sec.\nBut this didn’t happen. This means that as both are around 99-100% CPU bound, both require GIL to execute. Hence, when 1 thread acquires the GIL, the other thread waits to receive the GIL back… hence the time required was roughly the same. Practically they never ran truly parallelly.\nSo, how do we run threads truly concurrently in Cpython? Many times we don’t even realize the bottleneck capacity of Cpython as majority of times we are not working with purely python code, for example working with numpy array, numba etc. we can get away with using multithreading/without acquiring GIL as once GIL is acquired, python calls a C program which runs in the background, and hence in that time the GIL can be given to other thread.\nGIL History and Removal Efforts GIL was first introduced in 1999, and had several positive and negative ramifications:\nPositives:\nSimple Easy to get right No deadlocks as there is only one lock Single threading is fast! Good for I/O bound threads Negatives:\nBad for CPU bound tasks, as execution will always be on a single core. This was fine in 1992 as we would rarely see multi-core CPUs back then. But the world has changed! Unfortunately until and unless GIL is present this limitation would always be there, hence GIL removal has been a huge topic of discussion in the Cpython implementation.\nFigure DetailsFigure 4.2.2: https://peps.python.org/pep-0703/ In PEP - Python Enhancement Proposals - a proposal was made, to make the GIL optional, proposing to adding a build configuration and to let it run Python code without the global interpreter lock and with the necessary changes needed to make the interpreter thread-safe.\nOver the years, various efforts have been made to overcome the limitations posed by the GIL:\nFree-Threading (1996): An early attempt to address the GIL was called “free-threading,” but it didn’t fully remove the GIL and had its own set of complexities.\nGilectomy (2015): This initiative aimed to remove the GIL from CPython entirely. However, it turned out to be a challenging task due to the intricacies of Python’s memory management and extensive use of C libraries.\nRecent Developments: “nogil” have been proposed, which explore ways to make Python more thread-friendly and possibly eliminate the GIL. These proposals aim to allow more parallelism in certain scenarios.\nIn the following sections, we would compare the performance improvements of these efforts done by other people and see how much improvements they actually give and at what costs.\nThere are three important aspects of Python to consider if we want fast, free-threading in CPython:\nSingle-threaded performance\nParallelism\nMutability (the ability to change the state or content of objects in a programming language, meaning that mutable objects can be modified after they are created)\nThe last of these, mutability, is key.\nAlmost all of the work done on speeding up dynamic languages stems from original work done on the self programming language, but with many refinements. Most of this work has been on Javascript, which is single-threaded and less mutable than Python, but PyPy has also made some significant contributions. PyPy has a GIL.\nSelf is an object-oriented programming language based on the concept of prototypes,\nThere is also work on Ruby. Ruby is even more mutable than Python, but also has a GIL. Work on Ruby mirrors that on Javascript.\nThe JVM supports free threading, but Java objects are almost immutable compared to Python objects, and the performance of Python, Javascript and Ruby implementations on the JVM has been disappointing, historically.\nPerforming the optimizations necessary to make Python fast in a free-threading environment will need some original research. That makes it more costly and a lot more risky.\nThere are three options available to the Steering Council (with regard to PEP 703:\nChoose single-threading performance: We ultimately expect a 5x speedup over 3.10\nChoose free-threading: NoGIL appears to scale well, but expect worse single threaded performance.\nChoose both.\nThe pros and cons of the three options Option 1:\nPros: We know how to do this. We have a plan. It will happen. Sub-interpreters allow some limited form of parallelism.\nCons: It keeps the GIL, preventing free-threading.\nOption 2:\nPros: Free threading; much better performance for those who can use multiple threads effectively.\nCons: Some unknowns. Worse performance for most people, as single threaded performance will be worse. We don’t know how much worse.\nOption 3:\nPros: Gives us the world class runtime that the world’s number one programming language should have.\nCons: More unknowns and a large cost.\nFree-Threading Patch - link Released in 1996, the Free Threading patch was built for Python 1.4 by Greg Stein. Unfortunately, Python 1.4 is very old and cannot be built on modern systems of today’s times. Hence, we would be looking into benchmarkings done by Dave Beazley in 2011.\nFirst, he wrote a simple spin-loop and see what happened:\nUsing the original version of Python-1.4 (with the GIL), this code ran in about 1.9 seconds. Using the patched GIL-less version, it ran in about 12.7 seconds. That’s about 6.7 times slower. Yow!\nJust to further confirm his findings, he ran the included Tools/scripts/pystone.py benchmark (modified to run slightly longer in order to get more accurate timings).\nFirst, with the GIL:\nNow, without the GIL:\nHere, the GIL-less Python is only about 4 times slower.\nTo test threads,he wrote a small sample that subdivided the work across two worker threads is an embarrassingly parallel manner (note: this code is a little wonky due to the fact that Python-1.4 doesn’t implement thread joining–meaning that we have to do it ourselves with the included binary-semaphore lock).\nIf we run this code with the GIL, the execution time is about 2.5 seconds or approximately 1.3 times slower than the single-threaded version (1.9 seconds). Using the GIL-less Python, the execution time is 18.5 seconds or approximately 1.45 times slower than the single-threaded version (12.7 seconds). Just to emphasize, the GIL-less Python running with two-threads is running more than 7 times slower than the version with a GIL. Ah, but what about preemption you ask? If we return to the example above in the section about reentrancy, we will find that removing the GIL, does indeed, allow free threading and long-running calculations to be preempted. Success! Needless to say, there might be a few reasons why the patch quietly disappeared.\nGilectomy by Larry Hastings - link The earlier effort of removing GIL was more of a failure, as it worsened single thread performance as well as the multi threaded program ran slower compared running the same on single thread.\nHence, 3 political considerations Larry Hastings tried to keep in mind while building Gilectomy were -\nDon’t hurt single threaded performance\nDon’t break c extensions\nDon’t make it too complicated\nSo, the things he did were -\nKeep reference counting - It is a core functionality of Cpython and changing it would mean writing all the C APIs.\nUsed atomic incr/decr which comes free with Intel Processor. But is 30% slower off the top Global and static variables\nShared singletons - all variables (in thread implementation) are public everytime Atomicity - This is where the one big lock (GIL) would be replaced by smaller locks\nHence, a new lock api was introduce Here is a benchmarking code given by Larry Hastings himself, as the Gilectomy implementation has a lot of things like “str” etc. which don’t work as intended.\nTo benchmark, this code was run using both, Cpython (GIL) and Gilectomy (noGIL), on a 8 core, 2.80GHz system.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Code 4.4.1: Benchmarking Code of Gilectomy - # https://github.com/larryhastings/gilectomy/blob/gilectomy/x.py import threading import sys def fib(n): if n \u003c 2: return 1 return fib(n-1) + fib(n-2) def test(): print(fib(30)) threads = 1 #changing number of threads here if len(sys.argv) \u003e 1: threads = int(sys.argv[1]) for i in range(threads - 1): threading.Thread(target=test).start() if threads \u003e 0: test() This code performs a CPU intensive task of calculating fibonacci of a large number (30 in this case) and running that CPU heavy task on multiple threads.\nThis code was ran on both Cpython-3.11 and Gilectomy-3.6.0a1\nThe reason for providing a benchmarking code by Larry was that many **features in Cpython did not work as it is in this Gilectomy’s implementation of python. Something as simple as ‘str’ (string) had a very ambiguous behavior hence, he had to provide a code which could run on both Cpython and Gilectomy.\nFigure DetailsOutput 4.4.1 - Output for Benchmarking Code 4.4.1 Graph DetailsGraph 4.4.1 - Cpyton(GIL) vs Gilectomy(no GIL) Wall Time taken by code to complete execution - comparison on multithreaded code This graph represents the Wall Time difference in time taken by both the versions of Python. We can see the Gilectomy implementation is 2x times slower, which is not bad.\nGraph DetailsGraph 4.4.2 - Cpyton(GIL) vs Gilectomy(no GIL) CPU Time taken by code to complete execution - comparison on multithreaded code But here we can see that in terms of CPU time, Gilectomy is nearly 2x slower at 1 thread, but jumps to 10x slower at 2 threads and from there it keeps going up and up. At 17 cores, it is nearly 19-20 times slower.\nIn the context of this code, more CPU time is typically considered “bad” or inefficient. If you’re running multiple threads and each thread consumes a lot of CPU time, it can lead to high CPU utilization, potentially causing the system to become unresponsive for other tasks.\nWhat happened to Gilectomy later?\nThe last update in Pycon 2019 was that after significant work Larry Hastings was still able to get the performance of his non-GIL version to match that of to Python with the GIL, but with a significant caveat; the default Python version ran only on a single core (as expected) - the non-GIL version needed to run on 7 cores to keep up. Larry Hastings later admitted that work has stalled, and he needs a new approach since the general idea of trying to maintain the general reference counting system, but protect the reference counts without a Global lock is not tenable.\nnogil by Sam Gross - link nogil is a proof-of-concept implementation of CPython that supports multithreading without the global interpreter lock (GIL). The purpose of this project was to show -\nThat it is feasible to remove the GIL from Python.\nThat the tradeoffs are manageable and the effort to remove the GIL is worthwhile.\nThat the main technical ideas of this project (reference counting, allocator changes, and thread-safety scheme) should serve as a basis of such an effort.\nFigure DetailsFigure 4.5.1: nogil speed-up on the pyperformance benchmark suite compared to Python 3.9.0a3. Benchmarking across existing Cpython modules in nogil Python implementation to check speedup/speeddown Let’s test on the same code, but calculating fib of 40 now -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Code 4.5.1: Benchmarking code of CPU intensive task of calculating # fibonacci of a large number, code ran on both Cpython-3.11 # and nogil-3.9.10-1 import threading import sys def fib(n): if n \u003c 2: return 1 return fib(n-1) + fib(n-2) def test(): print(fib(40)) # test function that calculates fibonacci number threads = 7 # number of threads if len(sys.argv) \u003e 1: threads = int(sys.argv[1]) for i in range(threads - 1): threading.Thread(target=test).start() if threads \u003e 0: test() Figure DetailsOutput 4.5.1 - Output for Benchmarking Code 4.5.1 As we can see here, running code on nogil python implementation helped us to utilize more than 1 core at the same time without any restrictions, and all the 7 threads created are utilizing 100% of the respective CPUs.\nIn the same multithreaded process in a shared-memory multiprocessor environment, each thread in the process can run concurrently on a separate processor, resulting in parallel execution, which is true simultaneous execution.\nFigure DetailsFigure 4.5.2: nogil multithreaded execution - htop view of CPU utilization (7 threads) Meanwhile, creating 7 threads on Cpython implementation gives really poor performance, as even though 7 threads exist, only 1 of them is running truly at a particular moment.\nFigure DetailsFigure 4.5.3: Cpython multithreaded execution - htop view of CPU utilization (7 threads) The shear performance improvement in nogil implementation over Cpython is mind blowing, making us wonder the highs MultiThreading in Python can touch -\nGraph DetailsGraph 4.5.1: Cpyton(GIL) vs nogil CPU Time taken by code to complete execution - comparison on multithreaded code As it is clearly visible, nogil completely outperforms the Cpython, even giving better performance in a single threaded program.\nGraph DetailsGraph 4.5.2: Cpyton(GIL) vs nogil ratio of improvement in execution time - (nogil / Cpython) As clearly shown above, nogil can achieve upto 5x better performance in multithreaded programs, and gives slightly better performance in single thread as well.\nMultiprocessing The multiprocessing library allows Python programs to start and communicate with Python sub-processes. This allows for parallelism because each sub-process has its own Python interpreter (i.e., there’s a GIL per-process).\nCommunication between processes is limited and generally more expensive than communication between threads.\nObjects generally need to be serialized or copied to shared memory. Starting a sub-process is also more expensive than starting a thread, especially with the “spawn” implementation.\nStarting a thread takes ~100 µs, while spawning a sub-process takes ~50 ms (50,000 µs) due to Python re-initialization.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Code 5.1: Multiprocessing demonstration in python import multiprocessing def fib(n): if n \u003c 2: return 1 return fib(n-1) + fib(n-2) def test(): print(fib(50)) if __name__ == \"__main__\": p1 = multiprocessing.Process(target=test) # creating processes p2 = multiprocessing.Process(target=test) p1.start() # starting processes p2.start() p1.join() # waiting for processes to finish p2.join() # both processes finished print(\"Done!\") The multiprocessing library has a number of downsides.\nThe “fork” implementation is prone to deadlocks.\nMultiple processes are harder to debug than multiple threads. Sharing data between processes can be a performance bottleneck. For example, in PyTorch, which uses multiprocessing to parallelize data loading, copying Tensors to inter-process shared-memory is sometimes the most expensive operation in the data loading pipeline.\nAdditionally, many libraries don’t work well with multiple processes: for example CUDA doesn’t support “fork” and has limited IPC support.\nConclusion Seeing the level of improvement nogil is able to achieve, this is a big proof of a plausible world having a GIL-Free Python which increases multithreaded performance by many folds, having no negative impact on single threading. Even though there is a lot of work still pending, there is no doubt that the PEP 703 will be accepted in the near future, but only time will tell.\nReferences - discuss.python.org/t/a-fast-free-threading-python/27903\npython.org/ftp/python/contrib-09-Dec-1999/System/threading.README\nstackify.com/python-garbage-collection/\nLarry Hastings - Removing Python’s GIL: The Gilectomy - PyCon 2016\ndabeaz.blogspot.com/2011/08/inside-look-at-gil-removal-patch-of.html\npythoncapi.readthedocs.io/gilectomy.html\ngithub.com/larryhastings/gilectomy\ngithub.com/colesbury/nogil\ndocs.google.com/document/d/18CXhDb1ygxg-YXNBJNzfzZsDFosB5e6BfnXLlejd9l0\n",
  "wordCount" : "3771",
  "inLanguage": "en",
  "image": "https://aryaman.space/images/about.jpg","datePublished": "2023-12-17T00:00:00Z",
  "dateModified": "2023-12-17T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Aryaman Gupta"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://aryaman.space/blog/breaking-boundaries/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "aryaman.space",
    "logo": {
      "@type": "ImageObject",
      "url": "https://aryaman.space/images/favicon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://aryaman.space/" accesskey="h" title="aryaman.space (Alt + H)">aryaman.space</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://aryaman.space/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://aryaman.space/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://aryaman.space/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://aryaman.space/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://aryaman.space/papershelf/" title="Papershelf">
                    <span>Papershelf</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Breaking Boundaries
    </h1>
    <div class="post-description">
      An in-depth look at Python&#39;s GIL, its impact on performance, and efforts to overcome its limitations including Free-Threading, Gilectomy, and nogil implementations.
    </div>
    <div class="post-meta"><span title='2023-12-17 00:00:00 +0000 UTC'>December 17, 2023</span>&nbsp;·&nbsp;18 min&nbsp;·&nbsp;3771 words&nbsp;·&nbsp;Aryaman Gupta

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#need-for-simultaneous-execution-in-python">Need for Simultaneous Execution in Python</a>
      <ul>
        <li><a href="#simultaneous-execution-possibilities-in-python"><strong>Simultaneous Execution Possibilities in Python</strong></a></li>
        <li><a href="#threading"><strong>Threading</strong></a></li>
        <li><a href="#gil-what-is-gil"><strong>GIL?! What is GIL?</strong></a></li>
        <li><a href="#gil-history-and-removal-efforts"><strong>GIL History and Removal Efforts</strong></a>
          <ul>
            <li><a href="#the-pros-and-cons-of-the-three-options"><strong>The pros and cons of the three options</strong></a></li>
          </ul>
        </li>
        <li><a href="#free-threading-patch---linkhttpwwwpythonorgftppythoncontrib-09-dec-1999systemthreadingtargz"><strong>Free-Threading Patch</strong> - <a href="http://www.python.org/ftp/python/contrib-09-Dec-1999/System/threading.tar.gz">link</a></a></li>
        <li><a href="#gilectomy-by-larry-hastings---linkhttpsgithubcomlarryhastingsgilectomy"><strong>Gilectomy by Larry Hastings</strong> - <a href="https://github.com/larryhastings/gilectomy">link</a></a></li>
        <li><a href="#nogil-by-sam-gross---linkhttpsgithubcomcolesburynogil">nogil by Sam Gross - <a href="https://github.com/colesbury/nogil">link</a></a></li>
        <li><a href="#multiprocessing"><strong>Multiprocessing</strong></a></li>
        <li><a href="#conclusion">Conclusion</a></li>
        <li><a href="#references--">References -</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>Python faces challenges in fully exploiting the growing capabilities of modern hardware. As hardware continues to advance with more CPU cores, faster processors, and abundant memory, Python&rsquo;s inherent design and execution model can often fall short in taking full advantage of these resources. Its single-threaded nature and certain architectural choices can result in suboptimal performance in scenarios where parallelism and hardware acceleration are vital. This limitation prompts developers to seek alternative solutions, such as integrating Python with external libraries, languages, or technologies, to overcome these hardware-related constraints.</p>
<h2 id="need-for-simultaneous-execution-in-python">Need for Simultaneous Execution in Python<a hidden class="anchor" aria-hidden="true" href="#need-for-simultaneous-execution-in-python">#</a></h2>
<p>Python is widely praised for being easy to learn, easy to use, and highly versatile, supporting developer productivity. However, Python is also <strong>notoriously slow</strong>. Programs written in languages such as C++, Node.js, and Go can execute as much as 30-40 times faster than equivalent Python programs.</p>
<p><img alt="Performance comparison across programming languages" loading="lazy" src="/images/breaking-boundaries/image1.png"></p>
<details>
<summary>Table Details</summary>
Table 1.1: Courtesy of github project by Kostya M
</details>
<p>Even though Python is constantly being optimized to work faster, we simply can&rsquo;t rely on the basic single-threaded execution codes as they are too slow. Hence the need for simultaneous execution.</p>
<h3 id="simultaneous-execution-possibilities-in-python"><strong>Simultaneous Execution Possibilities in Python</strong><a hidden class="anchor" aria-hidden="true" href="#simultaneous-execution-possibilities-in-python">#</a></h3>
<p>Three big contenders for dealing with multiple tasks in Python:</p>
<ol>
<li>
<p><strong>Asyncio</strong>: In computer programming, <a href="https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)">asynchrony</a> encompasses events that occur independently of the primary program flow and methods for managing these events. In essence, asynchronization implies that you can proceed with executing other sections of code without the need to wait for a particular task to finish.</p>
<ul>
<li>Cooperative pausing/waiting</li>
<li>Good for I/O bound processes</li>
</ul>
</li>
<li>
<p><strong>Threading</strong>:</p>
<ol>
<li>Python runs on a single thread on a single CPU.</li>
<li>GIL is a global lock around the entire Python interpreter. In order to advance the interpreter state and run the Python code, a thread must require the GIL. Hence, it is possible to have multiple Python threads in the same process, but only one of them can be executing the Python code. While this happens, the rest must wait to receive the GIL.</li>
<li>Non-cooperative pausing/interrupting</li>
<li>Good for I/O bound</li>
<li>Good for long-running operations without blocking (e.g., GUI applications)</li>
</ol>
</li>
<li>
<p><strong>Multiprocessing</strong>:</p>
<ol>
<li>Create different processes which have their own GIL.</li>
<li>Better where all processes are completely independent of each other.</li>
</ol>
</li>
</ol>
<h3 id="threading"><strong>Threading</strong><a hidden class="anchor" aria-hidden="true" href="#threading">#</a></h3>
<p>Let&rsquo;s take a for loop as an example, this loop is a CPU-intensive task.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 4.1: CPU Intensive task example</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">DO</span> <span class="o">=</span> <span class="mi">100000000</span>
</span></span><span class="line"><span class="cl"><span class="n">ans</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="k">global</span> <span class="n">ans</span>
</span></span><span class="line"><span class="cl">   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">       <span class="n">ans</span> <span class="o">+=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">foo</span><span class="p">(</span><span class="n">DO</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="/images/breaking-boundaries/image2.png"></p>
<p>As this was a simple single threaded task, it took around 5 secs and was 99% CPU intensive.</p>
<p>Okay, so if I have 2 loops like this running on a single thread, it would take around 10s. This is very bad.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 4.2: Extension of Code 4.1, 2 CPU Intensive tasks</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">DO</span> <span class="o">=</span> <span class="mi">100000000</span>
</span></span><span class="line"><span class="cl"><span class="n">ans</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">global</span> <span class="n">ans</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">ans</span> <span class="o">+=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">foo</span><span class="p">(</span><span class="n">DO</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">foo</span><span class="p">(</span><span class="n">DO</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="/images/breaking-boundaries/image3.png"></p>
<p>No issues, as these are CPU intensive tasks, we can run both the tasks on different threads. Hence, simultaneous execution would help us run 2 threads simultaneously and concurrently and the time would be reduced by half.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 4.3: CPU Intensive tasks executed in different threads</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <span class="n">Thread</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">DO</span> <span class="o">=</span> <span class="mi">100000000</span>
</span></span><span class="line"><span class="cl"><span class="n">ans</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="k">global</span> <span class="n">ans</span>
</span></span><span class="line"><span class="cl">   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">       <span class="n">ans</span> <span class="o">+=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">t1</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">foo</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">DO</span><span class="o">//</span><span class="mi">2</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="n">t2</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">foo</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">DO</span><span class="o">//</span><span class="mi">2</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">t1</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">t2</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">t1</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">t2</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>If this was true multithreading, the time taken for a for loop of half the range of the previous example should be half of the previous time taken, i.e. around 2.5 sec.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image4.png"></p>
<p>But we can see it again took roughly the same time. Why is this happening? To understand this we need to look into the core concept of Cpython - GIL.</p>
<h3 id="gil-what-is-gil"><strong>GIL?! What is GIL?</strong><a hidden class="anchor" aria-hidden="true" href="#gil-what-is-gil">#</a></h3>
<p>Before discussing GIL, it is important to note that we are discussing this in terms of CPython.</p>
<ul>
<li>
<p><strong>Python</strong> - definition of programming language we know, PEP - python enhancement proposals</p>
</li>
<li>
<p><strong>Cpython</strong> - physical implementation of the ideas in &ldquo;Python&rdquo; in C language</p>
</li>
</ul>
<p>Generally when we talk about python, we refer to the Cpython implementation of the language only.</p>
<p>Moving forward -</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image5.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Code 4.1.1: foo function</div></details>
<p>I created a function foo() where I allocated a = 50.</p>
<p>50 will be stored in memory and the variable a would be pointing to it. So the <em>reference count</em> of the memory where 50 is stored would be 1. But now, when the function is finished, the memory location has to be cleared/dereferenced. Hence, the reference count would be decreased by 1.</p>
<blockquote>
<p><em>Reference counting in CPython - At a very basic level,</em> <em><strong>a Python object&rsquo;s reference count is incremented whenever the object is referenced, and it&rsquo;s decremented when an object is dereferenced</strong></em>*.*</p>
</blockquote>
<p>The memory deallocation is done in different ways in different languages but in python when the reference count of a memory location becomes 0, python knows that that memory location can be used for storing something else.</p>
<p>Example - Garbage collectors is used by java</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image6.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Code 4.1.2a: Reference Counting</div></details>
<p>Then, why do we get a <em>reference count</em> of &lsquo;a&rsquo; as 3 here?</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image7.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">FIgure 4.1.1: Reference Counting explanation</div></details>
<p>This is the reason.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image8.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Code 4.1.2b: Reference Counting</div></details>
<p>The main issue comes, when there is concurrency involved in python threads -</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image9.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Figure 4.1.2: Issue in concurrency  in python due to reference counting</div></details>
<p>Imagine 2 threads are running simultaneously, in CPython. Reference Count of memory location pointed by variable &lsquo;a&rsquo; is 3. Thread 1 and 2 ask what is the reference count of &lsquo;a&rsquo; and both get 3. Now I do &lsquo;b=a&rsquo; in thread 1 so the reference count increases to 4. At the same time I do &lsquo;c=a&rsquo; in thread 2 and it also updates the reference count to 4.</p>
<p><strong><mark>But shouldn&rsquo;t the reference count be 5? Race conditions occur in such cases.</mark></strong> <strong>Hence, the requirement for concurrency management or GIL (Global Interpreter Lock) is required</strong></p>
<p><img loading="lazy" src="/images/breaking-boundaries/image10.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Figure 4.1.3: The GLOBAL INTERPRETER LOCK helps maintain reference count</div></details>
<p>In a real scenario if I have 4 threads running concurrently, thread 1 acquires the GIL, does some computation and waits for some I/O. In that time, the GIL is transferred to thread 2 which again does some task and starts waiting for something, for example a mouse click in the GUI. Again the GIL is transferred to a different thread. That&rsquo;s why multithreading works in cpython.</p>
<p>But if I have 2 different threads and both want to work with the CPU, then GIL is not a good option.</p>
<blockquote>
<p>Python 1.0 (1994): Python was initially designed without the GIL. In its early versions, Python used a simple reference counting mechanism for memory management. However, this approach had limitations, especially when dealing with circular references, which could lead to memory leaks.</p>
<p>Python 1.5 (1999): With Python 1.5, Guido van Rossum, the creator of Python, introduced the Global Interpreter Lock (GIL) as a solution to the multi-threading problems.</p>
</blockquote>
<p>Referring back to the example code 4.3-</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 4.3: CPU Intensive tasks executed in different threads</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <span class="n">Thread</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">DO</span> <span class="o">=</span> <span class="mi">100000000</span>
</span></span><span class="line"><span class="cl"><span class="n">ans</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="k">global</span> <span class="n">ans</span>
</span></span><span class="line"><span class="cl">   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">       <span class="n">ans</span> <span class="o">+=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">t1</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">foo</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">DO</span><span class="o">//</span><span class="mi">2</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="n">t2</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">foo</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">DO</span><span class="o">//</span><span class="mi">2</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">t1</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">t2</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">t1</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">t2</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="/images/breaking-boundaries/image11.png"></p>
<p>If this was true multithreading, <strong>the time taken for a for loop of half the range of the previous example should be half of the previous time taken, i.e. around 2.5 sec.</strong></p>
<p>But this didn&rsquo;t happen. This means that as both are around 99-100% CPU bound, both require <strong>GIL</strong> to execute. Hence, when 1 thread acquires the GIL, the <strong>other thread waits</strong> to receive the GIL back&hellip; hence the time required was roughly the same. Practically they never ran truly parallelly.</p>
<p>So, how do we run threads truly concurrently in Cpython? Many times we don&rsquo;t even realize the bottleneck capacity of Cpython as majority of times we are not working with purely python code, for example working with numpy array, numba etc. we can get away with using multithreading/without acquiring GIL as once GIL is acquired, python calls a C program which runs in the background, and hence in that time the GIL can be given to other thread.</p>
<h3 id="gil-history-and-removal-efforts"><strong>GIL History and Removal Efforts</strong><a hidden class="anchor" aria-hidden="true" href="#gil-history-and-removal-efforts">#</a></h3>
<p>GIL was first introduced in 1999, and had several positive and negative ramifications:</p>
<ol>
<li>
<p>Positives:</p>
<ol>
<li>Simple</li>
<li>Easy to get right</li>
<li>No deadlocks as there is only one lock</li>
<li>Single threading is fast!</li>
<li>Good for I/O bound threads</li>
</ol>
</li>
<li>
<p>Negatives:</p>
<ol>
<li>Bad for CPU bound tasks, as execution will always be on a single core. This was fine in 1992 as we would rarely see multi-core CPUs back then. But the world has changed!</li>
</ol>
</li>
</ol>
<p>Unfortunately until and unless GIL is present this limitation would always be there, hence GIL removal has been a huge topic of discussion in the Cpython implementation.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image12.png"></p>
<p><img loading="lazy" src="/images/breaking-boundaries/image13.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Figure 4.2.2: https://peps.python.org/pep-0703/</div></details>
<p>In PEP - Python Enhancement Proposals - a <a href="https://peps.python.org/pep-0703/">proposal</a> was made, to make the GIL optional, proposing to adding a build configuration and to let it run Python code without the global interpreter lock and with the necessary changes needed to make the interpreter thread-safe.</p>
<p>Over the years, various efforts have been made to overcome the limitations posed by the GIL:</p>
<ol>
<li>
<p><strong>Free-Threading (1996):</strong> An early attempt to address the GIL was called &ldquo;free-threading,&rdquo; but it didn&rsquo;t fully remove the GIL and had its own set of complexities.</p>
</li>
<li>
<p><strong>Gilectomy (2015):</strong> This initiative aimed to remove the GIL from CPython entirely. However, it turned out to be a challenging task due to the intricacies of Python&rsquo;s memory management and extensive use of C libraries.</p>
</li>
<li>
<p><strong>Recent Developments:</strong> &ldquo;<strong>nogil</strong>&rdquo; have been proposed, which explore ways to make Python more thread-friendly and possibly eliminate the GIL. These proposals aim to allow more parallelism in certain scenarios.</p>
</li>
</ol>
<p>In the following sections, we would compare the performance improvements of these efforts done by other people and see how much improvements they actually give and at what costs.</p>
<p>There are <strong>three important aspects</strong> of Python to consider if we want fast, free-threading in CPython:</p>
<ol>
<li>
<p><strong>Single-threaded performance</strong></p>
</li>
<li>
<p><strong>Parallelism</strong></p>
</li>
<li>
<p><strong>Mutability</strong> (the ability to change the state or content of objects in a programming language, meaning that mutable objects can be modified after they are created)</p>
</li>
</ol>
<p>The last of these, mutability, is key.</p>
<p>Almost all of the work done on speeding up dynamic languages stems from original work done on the <em>self programming language,</em> but with many refinements. Most of this work has been on Javascript, which is single-threaded and less mutable than Python, but PyPy has also made some significant contributions. PyPy has a GIL.</p>
<p><em>Self is an object-oriented programming language based on the concept of prototypes,</em></p>
<p>There is also work on Ruby. Ruby is even more mutable than Python, but also has a GIL. Work on Ruby mirrors that on Javascript.</p>
<p>The JVM supports free threading, but Java objects are almost immutable compared to Python objects, and the performance of Python, Javascript and Ruby implementations on the JVM has been disappointing, historically.</p>
<p>Performing the optimizations necessary to make Python fast in a free-threading environment will <strong>need some original research</strong>. That makes it more costly and a lot more risky.</p>
<p>There are three options available to the Steering Council (with regard to PEP  703:</p>
<ol>
<li>
<p>Choose single-threading performance: We ultimately expect a 5x speedup over 3.10</p>
</li>
<li>
<p>Choose free-threading: NoGIL appears to scale well, but expect worse single threaded performance.</p>
</li>
<li>
<p>Choose both.</p>
</li>
</ol>
<h4 id="the-pros-and-cons-of-the-three-options"><strong>The pros and cons of the three options</strong><a hidden class="anchor" aria-hidden="true" href="#the-pros-and-cons-of-the-three-options">#</a></h4>
<p>Option 1:</p>
<ul>
<li>
<p>Pros: We know how to do this. We have a plan. It will happen. Sub-interpreters allow some limited form of parallelism.</p>
</li>
<li>
<p>Cons: It keeps the GIL, preventing free-threading.</p>
</li>
</ul>
<p>Option 2:</p>
<ul>
<li>
<p>Pros: Free threading; much better performance for those who can use multiple threads effectively.</p>
</li>
<li>
<p>Cons: Some unknowns. Worse performance for most people, as single threaded performance will be worse. We don&rsquo;t know how much worse.</p>
</li>
</ul>
<p>Option 3:</p>
<ul>
<li>
<p>Pros: Gives us the world class runtime that the world&rsquo;s number one programming language should have.</p>
</li>
<li>
<p>Cons: More unknowns and a large cost.</p>
</li>
</ul>
<h3 id="free-threading-patch---linkhttpwwwpythonorgftppythoncontrib-09-dec-1999systemthreadingtargz"><strong>Free-Threading Patch</strong> - <a href="http://www.python.org/ftp/python/contrib-09-Dec-1999/System/threading.tar.gz">link</a><a hidden class="anchor" aria-hidden="true" href="#free-threading-patch---linkhttpwwwpythonorgftppythoncontrib-09-dec-1999systemthreadingtargz">#</a></h3>
<blockquote>
<p><em>Released in 1996, the Free Threading patch was built for Python 1.4 by Greg Stein. Unfortunately, Python 1.4 is very old and cannot be built on modern systems of today&rsquo;s times. Hence, we would be looking into</em> <a href="http://dabeaz.blogspot.com/2011/08/inside-look-at-gil-removal-patch-of.html"><em>benchmarkings done by Dave Beazley</em></a> <em>in 2011.</em></p>
</blockquote>
<p>First, he wrote a simple spin-loop and see what happened:</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image14.png"></p>
<p>Using the original version of Python-1.4 (with the GIL), this code ran in about 1.9 seconds. Using the patched GIL-less version, it ran in about 12.7 seconds. <strong>That&rsquo;s about 6.7 times slower</strong>. Yow!</p>
<p>Just to further confirm his findings, he ran the included Tools/scripts/<a href="http://www.python.org/ftp/python/contrib-09-Dec-1999/System/threading.tar.gz">pystone.py</a> benchmark (modified to run slightly longer in order to get more accurate timings).</p>
<p>First, with the GIL:</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image15.png"></p>
<p>Now, without the GIL:</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image16.png"></p>
<p>Here, the <strong>GIL-less Python is only about 4 times slower.</strong></p>
<p>To test threads,he wrote a small sample that subdivided the work across two worker threads is an embarrassingly parallel manner (note: this code is a little wonky due to the fact that Python-1.4 doesn&rsquo;t implement thread joining&ndash;meaning that we have to do it ourselves with the included binary-semaphore lock).</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image17.png"></p>
<p>If we run this code with the GIL, the execution time is <strong>about 2.5 seconds or approximately 1.3 times slower than the single-threaded version</strong> (1.9 seconds). Using the <strong>GIL-less Python, the execution time is 18.5 seconds or approximately 1.45 times slower than the single-threaded version</strong> (12.7 seconds). <mark>Just to emphasize, the GIL-less Python running with two-threads is running more than</mark> <strong><mark>7 times slower</mark></strong> <mark>than the version with a GIL. </mark></p>
<p><em>Ah, but what about preemption you ask? If we return to the example above in the section about reentrancy, we will find that removing the GIL, does indeed, allow free threading and long-running calculations to be preempted. Success! Needless to say, there might be a few reasons why the patch quietly disappeared.</em></p>
<h3 id="gilectomy-by-larry-hastings---linkhttpsgithubcomlarryhastingsgilectomy"><strong>Gilectomy by Larry Hastings</strong> - <a href="https://github.com/larryhastings/gilectomy">link</a><a hidden class="anchor" aria-hidden="true" href="#gilectomy-by-larry-hastings---linkhttpsgithubcomlarryhastingsgilectomy">#</a></h3>
<p>The earlier effort of removing GIL was more of a failure, as it worsened single thread performance as well as the multi threaded program ran slower compared running the same on single thread.</p>
<p>Hence, <strong>3 political considerations</strong> Larry Hastings tried to keep in mind while building Gilectomy were -</p>
<ul>
<li>
<p>Don&rsquo;t hurt single threaded performance</p>
</li>
<li>
<p>Don&rsquo;t break c extensions</p>
</li>
<li>
<p>Don&rsquo;t make it too complicated</p>
</li>
</ul>
<p>So, the things he did were -</p>
<ol>
<li>
<p><strong>Keep reference counting</strong> - It is a core functionality of Cpython and changing it would mean writing all the C APIs.</p>
<ol>
<li>Used atomic incr/decr which comes free with Intel Processor. But is 30% slower off the top</li>
</ol>
</li>
<li>
<p><strong>Global and static variables</strong></p>
<ol>
<li><strong>Shared singletons - all variables (in thread implementation) are public everytime</strong></li>
</ol>
</li>
<li>
<p><strong>Atomicity</strong> - This is where the one big lock (GIL) would be replaced by smaller locks</p>
<ol>
<li>Hence, a new lock api was introduce</li>
</ol>
</li>
</ol>
<p><img loading="lazy" src="/images/breaking-boundaries/image18.jpeg"></p>
<p>Here is a benchmarking code given by  <em>Larry Hastings</em> himself, as the Gilectomy implementation has a lot of things like &ldquo;str&rdquo; etc. which don&rsquo;t work as intended.</p>
<p>To benchmark, this code was run using both, Cpython (GIL) and Gilectomy (noGIL), on a <strong>8 core, 2.80GHz system</strong>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 4.4.1: Benchmarking Code of Gilectomy - </span>
</span></span><span class="line"><span class="cl"><span class="c1"># https://github.com/larryhastings/gilectomy/blob/gilectomy/x.py</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">threading</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">sys</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fib</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">   <span class="k">return</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">   <span class="nb">print</span><span class="p">(</span><span class="n">fib</span><span class="p">(</span><span class="mi">30</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">threads</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1">#changing number of threads here</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">   <span class="n">threads</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">test</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">threads</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">   <span class="n">test</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>This code performs a CPU intensive task of calculating fibonacci of a large number (30 in this case) and running that CPU heavy task on multiple threads.</p>
<p><strong>This code was ran on both Cpython-3.11 and Gilectomy-3.6.0a1</strong></p>
<blockquote>
<p>The reason for providing a benchmarking code by Larry was that many **features in Cpython did not work as it is in this Gilectomy&rsquo;s implementation of python. Something as simple as &lsquo;str&rsquo; (string) had a very ambiguous behavior hence, he had to provide a code which could run on both Cpython and Gilectomy.</p>
</blockquote>
<p><img loading="lazy" src="/images/breaking-boundaries/image19.jpg"></p>
<p><img loading="lazy" src="/images/breaking-boundaries/image20.jpg"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Output 4.4.1 - Output for Benchmarking Code 4.4.1</div></details>
<p><img loading="lazy" src="/images/breaking-boundaries/image21.png"></p>
<details data-node-type="hn-details-summary"><summary>Graph Details</summary><div data-type="detailsContent">Graph 4.4.1 - Cpyton(GIL) vs Gilectomy(no GIL) Wall Time taken by code to complete execution - comparison on multithreaded code</div></details>
<p>This graph represents the Wall Time difference in time taken by both the versions of Python. We can see the Gilectomy implementation is <strong>2x times slower</strong>, which is not bad.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image22.png"></p>
<details data-node-type="hn-details-summary"><summary>Graph Details</summary><div data-type="detailsContent">Graph 4.4.2 - Cpyton(GIL) vs Gilectomy(no GIL) CPU Time taken by code to complete execution - comparison on multithreaded code</div></details>
<p>But here we can see that in terms of CPU time, Gilectomy is nearly 2x slower at 1 thread, but <strong>jumps to 10x slower at 2 threads</strong> and from there it keeps going up and up. At 17 cores, it is <strong>nearly 19-20 times slower</strong>.</p>
<blockquote>
<p><em>In the context of this code, more CPU time is typically considered &ldquo;bad&rdquo; or inefficient.</em> If you&rsquo;re running multiple threads and each thread consumes a lot of CPU time, it can lead to high CPU utilization, potentially causing the system to become unresponsive for other tasks.</p>
</blockquote>
<p><strong>What happened to Gilectomy later?</strong></p>
<p>The last update in Pycon 2019 was that after significant work <em>Larry Hastings</em> was still able to get the performance of his non-GIL version to match that of to Python with the GIL, but with a significant caveat; the default Python version ran only on a single core (as expected) - the non-GIL version needed to run on 7 cores to keep up. Larry Hastings later admitted that work has stalled, and he needs a new approach since the general idea of trying to maintain the general reference counting system, but protect the reference counts without a Global lock is not tenable.</p>
<h3 id="nogil-by-sam-gross---linkhttpsgithubcomcolesburynogil">nogil by Sam Gross - <a href="https://github.com/colesbury/nogil">link</a><a hidden class="anchor" aria-hidden="true" href="#nogil-by-sam-gross---linkhttpsgithubcomcolesburynogil">#</a></h3>
<p><em>nogil</em> is a <strong>proof-of-concept implementation</strong> of CPython that supports multithreading without the global interpreter lock (GIL). The purpose of this project was to show -</p>
<ol>
<li>
<p>That it is feasible to remove the GIL from Python.</p>
</li>
<li>
<p>That the tradeoffs are manageable and the effort to remove the GIL is worthwhile.</p>
</li>
<li>
<p>That the main technical ideas of this project (reference counting, allocator changes, and thread-safety scheme) should serve as a basis of such an effort.</p>
</li>
</ol>
<p><img loading="lazy" src="/images/breaking-boundaries/image23.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Figure 4.5.1: nogil speed-up on the pyperformance benchmark suite compared to Python 3.9.0a3. Benchmarking across existing Cpython modules in nogil Python implementation to check speedup/speeddown</div></details>
<p>Let&rsquo;s test on the same code, but calculating fib of 40 now -</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 4.5.1: Benchmarking code of CPU intensive task of calculating </span>
</span></span><span class="line"><span class="cl"><span class="c1">#             fibonacci of a large number, code ran on both  Cpython-3.11 </span>
</span></span><span class="line"><span class="cl"><span class="c1">#             and nogil-3.9.10-1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">threading</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">sys</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fib</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">   <span class="k">return</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">   <span class="nb">print</span><span class="p">(</span><span class="n">fib</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>  <span class="c1"># test function that calculates fibonacci number</span>
</span></span><span class="line"><span class="cl"><span class="n">threads</span> <span class="o">=</span> <span class="mi">7</span> <span class="c1"># number of threads</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">   <span class="n">threads</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">   <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">test</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">threads</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">   <span class="n">test</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="/images/breaking-boundaries/image24.jpg"></p>
<p><img loading="lazy" src="/images/breaking-boundaries/image25.jpg"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Output 4.5.1 - Output for Benchmarking Code 4.5.1</div></details>
<p>As we can see here, running code on <em>nogil</em> python implementation helped us to utilize <strong>more than 1 core at the same time without any restrictions</strong>, and all the 7 threads created are <strong>utilizing 100%</strong> of the respective <strong>CPU</strong>s.</p>
<p>In the same multithreaded process in a shared-memory multiprocessor environment, <strong>each thread in the process can run concurrently on a separate processor</strong>, resulting in parallel execution, which is true simultaneous execution.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image26.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Figure 4.5.2: nogil multithreaded execution - htop view of CPU utilization (7 threads)</div></details>
<p>Meanwhile, creating 7 threads on Cpython implementation gives really poor performance, as even though 7 threads exist, only 1 of them is running truly at a particular moment.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image27.png"></p>
<details data-node-type="hn-details-summary"><summary>Figure Details</summary><div data-type="detailsContent">Figure 4.5.3: Cpython multithreaded execution - htop view of CPU utilization (7 threads)</div></details>
<p>The shear performance improvement in nogil implementation over Cpython is mind blowing, making us wonder the highs MultiThreading in Python can touch -</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image28.png"></p>
<details data-node-type="hn-details-summary"><summary>Graph Details</summary><div data-type="detailsContent">Graph 4.5.1: Cpyton(GIL) vs nogil CPU Time taken by code to complete execution - comparison on multithreaded code</div></details>
<p>As it is clearly visible, nogil completely outperforms the Cpython, even giving better performance in a single threaded program.</p>
<p><img loading="lazy" src="/images/breaking-boundaries/image29.png"></p>
<details data-node-type="hn-details-summary"><summary>Graph Details</summary><div data-type="detailsContent">Graph 4.5.2: Cpyton(GIL) vs nogil ratio of improvement in execution time - (nogil / Cpython)</div></details>
<p>As clearly shown above, <strong>nogil can achieve upto 5x better performance</strong> in multithreaded programs, and gives slightly better performance in single thread as well.</p>
<h3 id="multiprocessing"><strong>Multiprocessing</strong><a hidden class="anchor" aria-hidden="true" href="#multiprocessing">#</a></h3>
<p>The multiprocessing library allows Python programs to start and communicate with Python sub-processes. This allows for parallelism because each sub-process has its own Python interpreter (i.e., there&rsquo;s a GIL per-process).</p>
<p><strong>Communication between processes is limited and generally more expensive than communication between threads</strong>.</p>
<p>Objects generally need to be serialized or copied to shared memory. Starting a sub-process is also more expensive than starting a thread, especially with the &ldquo;spawn&rdquo; implementation.</p>
<blockquote>
<p>Starting a thread takes ~100 µs, while spawning a sub-process takes ~50 ms (50,000 µs) due to Python re-initialization.</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Code 5.1: Multiprocessing demonstration in python</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">multiprocessing</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">fib</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">fib</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">   <span class="n">p1</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>    <span class="c1"># creating processes</span>
</span></span><span class="line"><span class="cl">   <span class="n">p2</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">   <span class="n">p1</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>    <span class="c1"># starting processes</span>
</span></span><span class="line"><span class="cl">   <span class="n">p2</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">   <span class="n">p1</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>      <span class="c1"># waiting for processes to finish</span>
</span></span><span class="line"><span class="cl">   <span class="n">p2</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="c1"># both processes finished</span>
</span></span><span class="line"><span class="cl">   <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Done!&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="/images/breaking-boundaries/image30.png"></p>
<p>The multiprocessing library has a number of downsides.</p>
<ol>
<li>
<p>The &ldquo;fork&rdquo; implementation is prone to deadlocks.</p>
</li>
<li>
<p>Multiple processes are harder to debug than multiple threads. Sharing data between processes can be a performance bottleneck. For example, in PyTorch, which uses multiprocessing to parallelize data loading, copying Tensors to inter-process shared-memory is sometimes the most expensive operation in the data loading pipeline.</p>
</li>
<li>
<p>Additionally, many libraries don&rsquo;t work well with multiple processes: for example CUDA doesn&rsquo;t support &ldquo;fork&rdquo; and has limited IPC support.</p>
</li>
</ol>
<h3 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h3>
<p>Seeing the level of improvement nogil is able to achieve, this is a big proof of a plausible world having a GIL-Free Python which increases multithreaded performance by many folds, having no negative impact on single threading. Even though there is a lot of work still pending, there is no doubt that the PEP 703 will be accepted in the near future, but only time will tell.</p>
<h3 id="references--">References -<a hidden class="anchor" aria-hidden="true" href="#references--">#</a></h3>
<ul>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">discuss.python.org/t/a-fast-free-threading-python/27903</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">python.org/ftp/python/contrib-09-Dec-1999/System/threading.README</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">stackify.com/python-garbage-collection/</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=P3AyI_u66Bw">Larry Hastings - Removing Python&rsquo;s GIL: The Gilectomy - PyCon 2016</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">dabeaz.blogspot.com/2011/08/inside-look-at-gil-removal-patch-of.html</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">pythoncapi.readthedocs.io/gilectomy.html</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">github.com/larryhastings/gilectomy</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">github.com/colesbury/nogil</a></p>
</li>
<li>
<p><a href="https://discuss.python.org/t/a-fast-free-threading-python/27903">docs.google.com/document/d/18CXhDb1ygxg-YXNBJNzfzZsDFosB5e6BfnXLlejd9l0</a></p>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://aryaman.space/tags/breaking-boundaries/">Breaking-Boundaries</a></li>
      <li><a href="https://aryaman.space/tags/gil/">Gil</a></li>
      <li><a href="https://aryaman.space/tags/no-gil/">No-Gil</a></li>
      <li><a href="https://aryaman.space/tags/python/">Python</a></li>
      <li><a href="https://aryaman.space/tags/multithreading/">Multithreading</a></li>
      <li><a href="https://aryaman.space/tags/aryaman-batcave/">Aryaman-Batcave</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://aryaman.space/blog/replication-and-sharding-in-mongo/">
    <span class="title">« Prev</span>
    <br>
    <span>Demystifying Replication and Sharding in MongoDB</span>
  </a>
  <a class="next" href="https://aryaman.space/blog/asynchronous-programming-in-python/">
    <span class="title">Next »</span>
    <br>
    <span>Asynchronous Programming in Python</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Breaking Boundaries on x"
            href="https://x.com/intent/tweet/?text=Breaking%20Boundaries&amp;url=https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f&amp;hashtags=breaking-boundaries%2cgil%2cno-gil%2cpython%2cmultithreading%2caryaman-batcave">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Breaking Boundaries on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f&amp;title=Breaking%20Boundaries&amp;summary=Breaking%20Boundaries&amp;source=https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Breaking Boundaries on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f&title=Breaking%20Boundaries">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Breaking Boundaries on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Breaking Boundaries on whatsapp"
            href="https://api.whatsapp.com/send?text=Breaking%20Boundaries%20-%20https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Breaking Boundaries on telegram"
            href="https://telegram.me/share/url?text=Breaking%20Boundaries&amp;url=https%3a%2f%2faryaman.space%2fblog%2fbreaking-boundaries%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://aryaman.space/">aryaman.space</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
